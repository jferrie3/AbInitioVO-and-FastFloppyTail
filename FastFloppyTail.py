#FORMAT OF ORIGINAL FLOPPY TAIL [KLEIGER, G ET. AL. "RAPID E2-E3 ASSEMBLY AND DISASSEMBLY ENABLE PROCESSICE UBIQUITYLATION OF CULLIN-RING UBIQUITIN LIGASE SUBSTRATES" CELL. 139(5): 957-968 2009]
##CENTROID MODE [NOT DISCLOSED POTENTIALLY RAMA ONLY]
###19 CYCLES: RANDOM: SMALL_180(40%), SHEAR_180(40%), FRAGMENT_3MER(20%)
###20TH CYCLE: MINIMIZATION
####5000 TOTAL CYCLES -> RECOVER LOW
##FULL-ATOM MODE [SCORE12]
###START BY REPACKING ALL IN TAIL/VICINITY OF TAIL FOLLOWED BY MINIMIZATION
###14 CYCLES: RANDOM: SMALL_4(50%), SHEAR_4(50%) FOLLOWED BY SINGLE ROTAMER_TRIALS
###15TH CYCLE:MINIMIZATION
###30TH CYCLE:REPACK THEN MINIMIZATION
####3000 CYCLES -> RECOVER LOW

# The Start-Up
from pyrosetta import *  #Comment
init()
from pyrosetta.rosetta.core.scoring import *
from pyrosetta.rosetta.core.scoring.methods import *
from pyrosetta.rosetta.core.scoring.methods import EnergyMethodOptions
from pyrosetta.rosetta.protocols.grafting import *
from pyrosetta.rosetta.protocols.simple_moves import *
from pyrosetta.rosetta.protocols.moves import *
from pyrosetta.rosetta.core.fragment import *
from pyrosetta.rosetta.protocols.minimization_packing import *
from math import exp, log, pi, sqrt
from random import random as rnd
import sys
import os
import numpy as np
import argparse
import re
import scipy.optimize as op
from scipy.interpolate import interp1d

# Argument Parsing
parser = argparse.ArgumentParser(description='Program')
parser.add_argument('-in', '--Input_FASTA_File', action='store', type=str, required=False,
	help='Name of the text file containing the FASTA sequence of the protein of interest. Carot should not be in same line as sequence, UniProt format preferred.')
parser.add_argument('-ftnstruct', '--Number_of_FloppyTail_Structures', action='store', type=str, required=False, default=400,
	help='Number of structures to sample during FloppyTail portion. Default = 400')
parser.add_argument('-t_frag', '--Three_Mer_Frag_Library', action='store', type=str, required=False,
	help='Name of the file containing the three-mer fragment library generated by disorder corrected method')
parser.add_argument('-cycles', '--FloppyTail_Cycles', action='store', type=str, required=False, default=1,
	help='Number of sampling cycles within each stage of FloppyTail, identical to increase_cycles flag in C++ ClassicAbInitio and AbRelax. Default 1')
parser.add_argument('-refinesubset', '--Refine_Subset', action='store', type=int, required=False, default=0,
	help='Only subjects the lowest X% of structures to Relax refinement where X is specified as input following flag. Default 0')
parser.add_argument('-relnstruct', '--Number_of_Relax_Structures', action='store', type=str, required=False, default=0,
	help='Number of independent full-atom Relax sampling trajectories from a single AbInitio structure. Default 0')
parser.add_argument('-diso', '--Disorder_Probability_Prediction_File', action='store', type=str, required=False,
	help='File containing per residue disorder probability prediction in RaptorX format. Generally acquired from RaptorX prediciton.')
parser.add_argument('-inpdb', '--Input_PDB_File', action='store', type=str, required=False,
	help='Name of the text file containing the PDB structure of the protein of interest. All residues are required, missing residues are not constructed')
parser.add_argument('-pymol', '--PYMOL', action='store_true', required=False,
	help='Running with this flag will utilize PyMOL Mover for visualization')
parser.add_argument('-rg', '--RG', action='store', type=float, required=False,
	help='Ability to provide radius of gyration via Ferrie et. al. JPCB 2020 rg score term')
parser.add_argument('-fold', '--Fold_Tree', action='store', type=str, required=False,
	help='Input FoldTree of form StartResidue,EndResidue,EdgeType. where . is use to separate Edges')
parser.add_argument('-d_seg_cut', '--Diso_Seg_Cutoff', action='store', type=int, required=False, default=10,
	help='Disorder Segment Cutoff: specifies the number of successive residues that qualifies as a disordered segment. Default 10')
parser.add_argument('-enableEB', '--Enable_End_Bias', action='store', type=bool, required=False,
	help='Enables End Biasing in fragment sampling. Only required if Fold Tree is submitted')
args = parser.parse_args()

## Imports from Parser and Defaults
ftnstruct = int(args.Number_of_FloppyTail_Structures)
cycles = int(args.FloppyTail_Cycles)
relnstruct = int(args.Number_of_Relax_Structures)
refine_number = int((args.Refine_Subset/100)*int(ftnstruct))
	
# Importing sequence from FASTA
if args.Input_FASTA_File:
	fasta_file = open(args.Input_FASTA_File, 'r')
	fasta_lines = fasta_file.readlines()
	fasta_counter = 0
	fasta_sequence = ' '
	for fasta_line in fasta_lines:
		if '>' not in fasta_line:
			if fasta_counter == 0:
				if '\n' in fasta_line:
					fasta_sequence = fasta_line.split('\n')[0]
				else:
					fasta_sequence = fasta_line
				fasta_counter = 1	
			else:
				if '\n' in fasta_line:
					fasta_sequence = fasta_sequence + fasta_line.split('\n')[0]
				else:
					fasta_sequence = fasta_sequence + fasta_line

# Determining the Per Residue Disorder Probability and Number of Segments
if args.Disorder_Probability_Prediction_File:
	disorder_dtypes = [('res_num', np.float_), ('AA', np.unicode_, 2), ('ast', np.unicode_, 1), ('disprob', np.float_)]
	disorder_dat = np.genfromtxt(args.Disorder_Probability_Prediction_File, dtype=disorder_dtypes, delimiter=' ', skip_header=3)
	diso_dat = np.empty((len(disorder_dat),1))
	diso_segments = []
	diso_cutoff = 0.5
	seg_cutoff = args.Diso_Seg_Cutoff #10
	seg_res_counter = 0
	per_residue_disorder = 0
	diso_current = disorder_dat[0][3]
	segment_break_list = []
	segment_switch = False
	for seg_residue in range(len(disorder_dat)):
		if disorder_dat[seg_residue][3] >= diso_cutoff and diso_current >= diso_cutoff:
			seg_res_counter = 0
		elif disorder_dat[seg_residue][3] < diso_cutoff and diso_current < diso_cutoff:
			seg_res_counter = 0
		elif disorder_dat[seg_residue][3] < diso_cutoff and diso_current >= diso_cutoff:
			seg_res_counter = seg_res_counter + 1
		elif disorder_dat[seg_residue][3] >= diso_cutoff and diso_current < diso_cutoff:
			seg_res_counter = seg_res_counter + 1
		if seg_res_counter > args.Diso_Seg_Cutoff - 1: #9:
			seg_res_counter = 0
			diso_current = disorder_dat[seg_residue][3]
			if diso_current >= diso_cutoff:
				transition_id = 'order' # meaning all residues prior to end are ordered
			else:
				transition_id = 'disorder' # meaning all residues prior to end are disordered
			segment_break_list.append((seg_residue-(args.Diso_Seg_Cutoff-1), transition_id)) #9
		per_residue_disorder = per_residue_disorder + (disorder_dat[seg_residue][3]/float(len(disorder_dat)))
	if disorder_dat[len(disorder_dat)-1][3] >= diso_cutoff:
		segment_break_list.append((len(disorder_dat), 'disorder'))
	else:
		segment_break_list.append((len(disorder_dat), 'order'))	

# Adding PTMs
def MakePTMMutations(pose, fasta_sequence):
	ptm_mutation_list = re.findall("\[(.*?)\]", fasta_sequence)
	residue_mutation_list = []
	pose_sequence = pose.sequence()
	residue_number = 0
	ptm_number = 0
	count_residue = True
	for res in fasta_sequence:
		if res == '[':
			count_residue = False
			residue_mutation_list.append(residue_number)
		if count_residue == True:
			residue_number +=1	
		if res == ']':
			count_residue = True
	print(ptm_mutation_list)
	print(residue_mutation_list)
	for res_ptm_idx, res_ptm in enumerate(ptm_mutation_list):
		mutate = MutateResidue(residue_mutation_list[res_ptm_idx], res_ptm)
		mutate.apply(pose)
	return pose	
			

# The Poses
p=Pose()
if args.Input_FASTA_File:
	p = pose_from_sequence(fasta_sequence, "centroid")
if args.Input_PDB_File:
	p = pose_from_pdb(str(args.Input_PDB_File))
	if args.Input_FASTA_File:
		if p.sequence() != fasta_sequence:
			if '_p:' in fasta_sequence:
				p = MakePTMMutations(p, fasta_sequence)

starting_p = Pose()
starting_p.assign(p)
pvdw = Pose()
pvdwc = Pose()
pcen = Pose()
cenmap = MoveMap()
cenmap.set_bb(True)
fullmap = MoveMap()
fullmap.set_bb(True)
fullmap.set_chi(True)
cenmap_min = MoveMap()
cenmap_min.set_bb(True)
fullmap_min = MoveMap()
fullmap_min.set_bb(True)
fullmap_min.set_chi(True)
relaxmap = MoveMap()
relaxmap.set_bb(True)
relaxmap.set_chi(True)
if args.Disorder_Probability_Prediction_File:
	cenmap.set_bb(False)
	fullmap.set_bb(False)
	fullmap.set_chi(False)
	cenmap_min.set_bb(False)
	fullmap_min.set_bb(False)
	fullmap_min.set_chi(False)
	relaxmap.set_bb(False)
	relaxmap.set_chi(False)
	for res_seg_idx, res_seg_item in enumerate(segment_break_list):
		start_res = 1
		if res_seg_idx > 0:
			start_res = segment_break_list[res_seg_idx-1][0] + 1
		end_res = res_seg_item[0] + 1
		if res_seg_item[1] == 'disorder':
			for res_idx in range(start_res,end_res):
				cenmap.set_bb(res_idx, True)
				fullmap.set_bb(res_idx, True)
				fullmap.set_chi(res_idx, True)
				cenmap_min.set_bb(res_idx, True)
				fullmap_min.set_bb(res_idx, True)
				fullmap_min.set_chi(res_idx, True)
				relaxmap.set_bb(res_idx, True)
				relaxmap.set_chi(res_idx, True)
		else:
			continue
			
if args.Fold_Tree:
	fold_tree_input = []
	fold_tree_list = args.Fold_Tree.split('.')
	for fold_item in fold_tree_list:
		fold_tree_input.append(fold_item.split(','))
	fold_tree = FoldTree()
	for fold in fold_tree_input:
		fold_tree.add_edge(int(fold[0]),int(fold[1]),int(fold[2]))
	starting_p.fold_tree(fold_tree)
	p.fold_tree(fold_tree)
	
# The Score Functions
# Adding an RG Constraint
if args.RG:
	##### Computing the Expected Radius of Gyration
	rg_b = 0.38 # in nanometers
	rg_lp = 0.53 # in nanometers
	gamma = 1.1615
	seq_N = len(p.sequence())
	# Solving for scaling from Rg
	def v_from_pr(var_a):
		return ((np.sqrt((2*rg_lp*rg_b)/((2*var_a+1)*(2*var_a+2)))*(seq_N**var_a))*10)-args.RG # in Angstroms
	seq_v0 = 1.0
	seq_v1 = op.fsolve(v_from_pr, seq_v0)
	var_g = (gamma-1)/seq_v1
	var_delta = 1/(1-seq_v1)
	r_set=np.arange(0.0,7*args.RG,0.01)
	saw_inputs = (r_set, args.RG, var_g, var_delta)
	## Concocting the Potential
	def pr_saw(var_a, input_vars):
		r, rg, g, delta = input_vars
		return (var_a[0]*4*np.pi/rg)*((r/rg)**(2+g))*np.exp(-var_a[1]*((r/rg)**delta))
	
	def solve_pr_saw(var_a, *input_vars):
		r, rg, g, delta = input_vars
		return (np.sum((var_a[0]*4*np.pi/rg)*((r/rg)**(2+g))*np.exp(-var_a[1]*((r/rg)**delta)))-1, np.sum((var_a[0]*4*np.pi/rg)*((r/rg)**(2+g))*np.exp(-var_a[1]*((r/rg)**delta))*(r**2))-rg**2)
	a0 = [1.0, 1.0]
	a1 = op.fsolve(solve_pr_saw,a0,args=saw_inputs)
	rg_sf_term_potential = interp1d(r_set, (1-(pr_saw(a1, saw_inputs)/np.max(pr_saw(a1, saw_inputs)))))
	
	## Making the Actual Score Term
	from pyrosetta.rosetta.core.scoring.methods import ContextIndependentOneBodyEnergy ## newer versions make this pyrosetta.rosetta
	@pyrosetta.EnergyMethod() ## for newer versions make pyrosetta.EnergyMethod()
	class SeqCorrRgMethod(WholeStructureEnergy):
		"""A scoring method that using a predicted radius of gyration from the
		primary sequence to construct a polymer-scaled potential
	
		"""
		def __init__(self):
			"""Construct LengthScoreMethod."""
			WholeStructureEnergy.__init__(self, self.creator())
	
		def finalize_total_energy(self, pose, sfxn, emap):
			"""Calculate energy of res of pose and emap"""
			pose = pose ## for newer versions remove line
			e_val = 0
			r_xyz = np.zeros([seq_N, 3])
			rg_sq = np.zeros([seq_N, 1])
			start_res = 1
			end_res = seq_N
			
			for res_num in range(start_res, end_res, 1):
				for res_xyz in range(len(r_xyz[0])):
					r_xyz[res_num-start_res][res_xyz] = pose.residue(res_num).nbr_atom_xyz()[res_xyz]
			r_cen_mass = np.average(r_xyz, axis=0)
			for res_num in range(len(r_xyz)):
				rg_sq[res_num] = (np.linalg.norm(r_xyz[res_num] - r_cen_mass))**2
			rg_val = np.sqrt(np.average(rg_sq))
			if rg_val < 7*args.RG:
				e_val = e_val + float(rg_sf_term_potential(rg_val))
			else:
				e_val = e_val + float(rg_sf_term_potential(6.9*args.RG))	
			emap.set(self.scoreType, e_val) ## for newer versions remove .get()
	
	new_rg_score = SeqCorrRgMethod.scoreType
	
## VDW Repulsive Score Function
sf_stage_0 = create_score_function('score0')
if args.RG:
	sf_stage_0.set_weight(new_rg_score, (400/24)*5)

## Centroid Score Functions
sf_stage_1 = create_score_function('cen_std')
sf_stage_1.set_weight(rama, 1.0)
sf_stage_1.set_weight(cenpack, 1.0)
sf_stage_1.set_weight(hbond_lr_bb, 1.0)
sf_stage_1.set_weight(hbond_sr_bb, 1.0)
if args.RG:
	sf_stage_1.set_weight(new_rg_score, (400/24)*5)
	
## Full Atom Score Functions
sf_stage_2 = create_score_function('ref2015')
if args.RG:
	sf_stage_2.set_weight(new_rg_score, (400/24)*500)
sf_relax = create_score_function('ref2015_cart')

## Radius of Gyration Reference Score Function
sfrg = ScoreFunction()
sfrg.set_weight(rg, 1.0)

# The Movers
## Fragment Movers
# Importing the Fragment Files
if args.Three_Mer_Frag_Library:
	fragset3 = ConstantLengthFragSet(3)
	fragset3.read_fragment_file(args.Three_Mer_Frag_Library)
	# Constructing the Fragment Mover
	fragmover3 = ClassicFragmentMover(fragset3, cenmap)
	if args.Fold_Tree:
		if not args.Enable_End_Bias:
			fragmover3.enable_end_bias_check(False)

## Minimization Movers
vdwmin = MinMover()
vdwmin.movemap(cenmap_min)
vdwmin.score_function(sf_stage_0)
vdwmin.min_type('linmin')

cenmin = MinMover()
cenmin.movemap(cenmap_min)
cenmin.score_function(sf_stage_1)
cenmin.min_type('linmin')

fullmin = MinMover()
fullmin.movemap(fullmap_min)
fullmin.score_function(sf_stage_2)
fullmin.min_type('linmin')

## Phi-Psi Movers
vdw_small_mover = SmallMover(cenmap, 1.0, 1)
vdw_shear_mover = ShearMover(cenmap, 1.0, 1)
vdw_small_mover.angle_max(180)
vdw_small_mover.angle_max("H", 180)
vdw_small_mover.angle_max("E", 180)
vdw_small_mover.angle_max("L", 180)
vdw_shear_mover.angle_max(180)
vdw_shear_mover.angle_max("H", 180)
vdw_shear_mover.angle_max("E", 180)
vdw_shear_mover.angle_max("L", 180)
random_stage_0 = RandomMover()
random_stage_0.add_mover(vdw_small_mover)
random_stage_0.add_mover(vdw_shear_mover)
vdwrepeat = RepeatMover(random_stage_0, 7)

cen_small_mover = SmallMover(cenmap, 0.8, 1)
cen_shear_mover = ShearMover(cenmap, 0.8, 1)
cen_small_mover.angle_max(180)
cen_small_mover.angle_max("H", 180)
cen_small_mover.angle_max("E", 180)
cen_small_mover.angle_max("L", 180)
cen_shear_mover.angle_max(180)
cen_shear_mover.angle_max("H", 180)
cen_shear_mover.angle_max("E", 180)
cen_shear_mover.angle_max("L", 180)

random_stage_1 = RandomMover()
random_stage_1.add_mover(cen_small_mover)
random_stage_1.add_mover(cen_small_mover)
random_stage_1.add_mover(cen_small_mover)
random_stage_1.add_mover(cen_small_mover)
random_stage_1.add_mover(cen_shear_mover)
random_stage_1.add_mover(cen_shear_mover)
random_stage_1.add_mover(cen_shear_mover)
random_stage_1.add_mover(cen_shear_mover)
if args.Three_Mer_Frag_Library:
	random_stage_1.add_mover(fragmover3)
	random_stage_1.add_mover(fragmover3)

full_small_mover = SmallMover(fullmap, 0.8, 1)
full_shear_mover = ShearMover(fullmap, 0.8, 1)
full_small_mover.angle_max(4)
full_small_mover.angle_max("H", 4)
full_small_mover.angle_max("E", 4)
full_small_mover.angle_max("L", 4)
full_shear_mover.angle_max(4)
full_shear_mover.angle_max("H", 4)
full_shear_mover.angle_max("E", 4)
full_shear_mover.angle_max("L", 4)
full_random = RandomMover()
full_random.add_mover(full_small_mover)
full_random.add_mover(full_shear_mover) 

## Packing/Rotamer Movers
## Converting the Pose
switch = SwitchResidueTypeSetMover('fa_standard')
switch_cen = SwitchResidueTypeSetMover('centroid')

### The Task Operations
if p.is_centroid() == True:
	switch.apply(p)
else:
	switch_cen.apply(starting_p)

fulltask = standard_packer_task(p)
fulltask.restrict_to_repacking()
switch_cen.apply(p)

### The Rotamer Movers
fullpack = PackRotamersMover(sf_stage_2, fulltask)
fullrottrial = RotamerTrialsMover(sf_stage_2, fulltask)

## Sequence Movers
random_stage_0 = SequenceMover()
random_stage_0.add_mover(vdwrepeat)
random_stage_0.add_mover(vdwmin)

random_stage_2 = SequenceMover()
random_stage_2.add_mover(full_random)
#random_stage_2.add_mover(fullrottrial)

## Setting up the Monte-Carlo
mc_stage_0 = MonteCarlo(p, sf_stage_0, 10.0)
mc_stage_1 = MonteCarlo(p, sf_stage_1, 1.0)
switch.apply(p)
mc_stage_2 = MonteCarlo(p, sf_stage_2, 1.0)
switch_cen.apply(p)

## Setting up Trial Movers
trial_stage_0 = TrialMover(random_stage_0, mc_stage_0)
trial_stage_1a = TrialMover(random_stage_1, mc_stage_1)
trial_stage_1b = TrialMover(cenmin, mc_stage_1)
trial_stage_2a = TrialMover(random_stage_2, mc_stage_2)
trial_stage_2b = TrialMover(fullmin, mc_stage_2)
trial_stage_2c = TrialMover(fullpack, mc_stage_2)

trial_stage_0.keep_stats_type(pyrosetta.rosetta.protocols.moves.StatsType.no_stats)
trial_stage_1a.keep_stats_type(pyrosetta.rosetta.protocols.moves.StatsType.no_stats)
trial_stage_1b.keep_stats_type(pyrosetta.rosetta.protocols.moves.StatsType.no_stats)
trial_stage_2a.keep_stats_type(pyrosetta.rosetta.protocols.moves.StatsType.no_stats)
trial_stage_2b.keep_stats_type(pyrosetta.rosetta.protocols.moves.StatsType.no_stats)
trial_stage_2c.keep_stats_type(pyrosetta.rosetta.protocols.moves.StatsType.no_stats)

## Setting up Repeat Movers
stage_0 = RepeatMover(trial_stage_0, 1000)
stage_1a = RepeatMover(trial_stage_1a, 19)
stage_1b = RepeatMover(trial_stage_1b, 1)
stage_2a = RepeatMover(trial_stage_2a, 14)
stage_2b = RepeatMover(trial_stage_2b, 1)
stage_2c = RepeatMover(trial_stage_2c, 1)

# Setting up FastRelax
relax = rosetta.protocols.relax.FastRelax()
relax.min_type('lbfgs_armijo_nonmonotone')
relax.dualspace(True)
relax.set_scorefxn(sf_relax)
relax.max_iter(200)
relax.set_movemap(relaxmap)
if args.PYMOL:
	pmm = PyMOLMover()

# The Simulation and Output
for i in range(ftnstruct):
	p.assign(starting_p)
	if args.PYMOL:
		pmm.apply(p)
	stage_0.apply(p)
	if args.PYMOL:
		pmm.apply(p)
	mc_stage_0.reset(p)
	mc_stage_1.reset(p)
	for j in range(cycles*250):
		stage_1a.apply(p)
		mc_stage_1.recover_low(p)
		if args.PYMOL:
			pmm.apply(p)
		stage_1b.apply(p)
		mc_stage_1.recover_low(p)
		if args.PYMOL:
			pmm.apply(p)
		if j % 50 == 0:
			sf_stage_1.show(p)
			if args.RG:
				print(' Target Rg: ' + str(args.RG) + ' Current Rg: ' + str(sfrg(p)))
	mc_stage_1.recover_low(p)
	if args.PYMOL:
		pmm.apply(p)
	switch.apply(p)
	mc_stage_2.reset(p)
	for k in range(cycles*100):
		stage_2a.apply(p)
		mc_stage_2.recover_low(p)
		if args.PYMOL:
			pmm.apply(p)
		stage_2b.apply(p)
		mc_stage_2.recover_low(p)
		if args.PYMOL:
			pmm.apply(p)
		stage_2a.apply(p)
		mc_stage_2.recover_low(p)
		if args.PYMOL:
			pmm.apply(p)
		stage_2c.apply(p)
		mc_stage_2.recover_low(p)
		if args.PYMOL:
			pmm.apply(p)
		stage_2b.apply(p)
		mc_stage_2.recover_low(p)
		if args.PYMOL:
			pmm.apply(p)
		if k % 25 == 0:
			sf_stage_2.show(p)
			if args.RG:
				print(' Target Rg: ' + str(args.RG) + ' Current Rg: ' + str(sfrg(p)))
	mc_stage_2.recover_low(p)	
	if args.PYMOL:
		pmm.apply(p)
	outf = open("FloppyTail.sc", 'a')
	pdb_out = "FloppyTail_out_%i.pdb" %i
	outf.write("%s\t%.3f\t%.3f\n" % (pdb_out, sf_stage_2(p), sfrg(p)))
	p.dump_pdb(pdb_out)
	outf.close()
	
## Deciding who to minimize
dtype_list = [('out_name','S50'),('full_sc',float),('out_rg',float)]
ft_out_data = np.genfromtxt('FloppyTail.sc', dtype=dtype_list)
ft_out_sort = np.sort(ft_out_data, order='full_sc')
for ft_out_struct_idx in range(refine_number):
	ft_out_struct_item = ft_out_data[ft_out_struct_idx]['out_name']
	relax_p_in = pose_from_pdb(str(ft_out_struct_item))
	relax_p = Pose()
	print('Relaxing Output ' + str(ft_out_struct_idx+1) + ' of ' + str(refine_number))
	for relnstruct_idx in range(relnstruct):
		relax_p.assign(relax_p_in)
		relax.apply(relax_p)
		sfrelax.show(relax_p)
		outf = open("Relaxed_FloppyTail.sc", 'a')
		pdb_out = "Relaxed_" + str(ft_out_struct_idx) + "_" + str(relnstruct_idx) + ".pdb" 
		outf.write("%s\t%s\t%.4f\t%.4f\n" % (pdb_out, str(ft_out_struct_item), sfrelax(relax_p), sfrg(relax_p)))
		relax_p.dump_pdb(pdb_out)
		outf.close()	